import json
import re
import os

def extract_all_japanese_text_complete(txt_file_path):
    """
    æå–æ—¥è¯­æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼Œç¡®ä¿ä¸€æ¡ä¸æ¼
    """
    try:
        with open(txt_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"ğŸ“– è¯»å–æ—¥è¯­ç¿»è¯‘æ–‡ä»¶ï¼Œæ€»é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # ç§»é™¤æ‰€æœ‰æ ¼å¼æ ‡è®°ï¼Œåªä¿ç•™å®é™…æ–‡æœ¬å†…å®¹
        lines = content.split('\n')
        japanese_texts = []
        
        for line in lines:
            line = line.strip()
            # è·³è¿‡ç©ºè¡Œå’Œæ ¼å¼æ ‡è®°è¡Œ
            if (line and 
                not line.startswith('=== ç¬¬') and 
                not line.startswith('ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯') and
                not re.match(r'^\s*$', line)):
                japanese_texts.append(line)
        
        print(f"ğŸ“ æå–åˆ° {len(japanese_texts)} æ¡æ—¥è¯­æ–‡æœ¬")
        
        # æ˜¾ç¤ºå‰å‡ æ¡å†…å®¹
        for i, text in enumerate(japanese_texts[:5]):
            print(f"   {i+1}: {text[:50]}...")
        
        return japanese_texts
    
    except Exception as e:
        print(f"âŒ æå–æ—¥è¯­æ–‡æœ¬æ—¶å‡ºé”™: {e}")
        return []

def get_all_text_positions(json_path):
    """
    è·å–JSONä¸­æ‰€æœ‰æ–‡æœ¬çš„ä½ç½®ä¿¡æ¯
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            slides_data = json.load(f)
        
        text_positions = []
        all_contents = []
        
        for slide_idx, slide in enumerate(slides_data):
            texts = slide.get('texts', [])
            for text_idx, text_obj in enumerate(texts):
                content = text_obj.get('content', '').strip()
                if content:  # åªè¦æœ‰å†…å®¹å°±è®°å½•
                    text_positions.append((slide_idx, text_idx))
                    all_contents.append(content)
        
        print(f"ğŸ“ JSONä¸­å…±æœ‰ {len(text_positions)} ä¸ªæ–‡æœ¬ä½ç½®")
        
        return text_positions, all_contents
    
    except Exception as e:
        print(f"âŒ è·å–æ–‡æœ¬ä½ç½®æ—¶å‡ºé”™: {e}")
        return [], []

def complete_replacement(original_json_path, japanese_txt_path, output_json_path):
    """
    å®Œå…¨æ›¿æ¢ç­–ç•¥ï¼šç¡®ä¿æ‰€æœ‰æ—¥è¯­æ–‡æœ¬éƒ½è¢«ä½¿ç”¨ï¼Œæ‰€æœ‰åŸæ–‡æœ¬éƒ½è¢«æ›¿æ¢
    """
    
    # è¯»å–åŸå§‹JSONæ–‡ä»¶
    with open(original_json_path, 'r', encoding='utf-8') as f:
        slides_data = json.load(f)
    
    # æå–æ‰€æœ‰æ—¥è¯­æ–‡æœ¬
    japanese_texts = extract_all_japanese_text_complete(japanese_txt_path)
    
    # è·å–æ‰€æœ‰æ–‡æœ¬ä½ç½®
    text_positions, original_contents = get_all_text_positions(original_json_path)
    
    if not japanese_texts:
        print("âŒ æœªæ‰¾åˆ°æ—¥è¯­æ–‡æœ¬")
        return
    
    if not text_positions:
        print("âŒ æœªæ‰¾åˆ°æ–‡æœ¬ä½ç½®")
        return
    
    print(f"\nğŸ”„ å¼€å§‹å®Œå…¨æ›¿æ¢...")
    print(f"ğŸ“Š æ—¥è¯­æ–‡æœ¬æ•°é‡: {len(japanese_texts)}")
    print(f"ğŸ“Š JSONæ–‡æœ¬ä½ç½®: {len(text_positions)}")
    
    # ç­–ç•¥ï¼šå¾ªç¯ä½¿ç”¨æ—¥è¯­æ–‡æœ¬ï¼Œç¡®ä¿æ‰€æœ‰ä½ç½®éƒ½è¢«å¡«å……
    japanese_index = 0
    replaced_count = 0
    
    for i, (slide_idx, text_idx) in enumerate(text_positions):
        # å¾ªç¯ä½¿ç”¨æ—¥è¯­æ–‡æœ¬
        if japanese_index >= len(japanese_texts):
            japanese_index = 0
        
        old_content = slides_data[slide_idx]['texts'][text_idx]['content']
        new_content = japanese_texts[japanese_index]
        
        slides_data[slide_idx]['texts'][text_idx]['content'] = new_content
        
        print(f"   âœ… ä½ç½® {i+1}: '{old_content[:30]}...' â†’ '{new_content[:30]}...'")
        
        japanese_index += 1
        replaced_count += 1
    
    # å¦‚æœæ—¥è¯­æ–‡æœ¬è¿˜æœ‰å‰©ä½™ï¼Œæ·»åŠ åˆ°æœ€åä¸€é¡µ
    remaining_japanese = japanese_texts[japanese_index:]
    if remaining_japanese:
        print(f"\nğŸ“‹ è¿˜æœ‰ {len(remaining_japanese)} æ¡æ—¥è¯­æ–‡æœ¬æœªä½¿ç”¨ï¼Œæ·»åŠ åˆ°æœ€åä¸€é¡µ...")
        
        # æ‰¾åˆ°æœ€åä¸€é¡µ
        if slides_data:
            last_slide = slides_data[-1]
            if 'texts' not in last_slide:
                last_slide['texts'] = []
            
            # ä¸ºå‰©ä½™çš„æ—¥è¯­æ–‡æœ¬åˆ›å»ºæ–°çš„æ–‡æœ¬å¯¹è±¡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸åŒ…å«ä½ç½®ä¿¡æ¯ï¼‰
            for remaining_text in remaining_japanese:
                new_text_obj = {
                    "content": remaining_text
                }
                last_slide['texts'].append(new_text_obj)
                print(f"   â• æ·»åŠ : '{remaining_text[:30]}...'")
                replaced_count += 1
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜å®Œå…¨æ›¿æ¢åçš„JSONæ–‡ä»¶...")
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(slides_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å®Œå…¨æ›¿æ¢å®Œæˆï¼")
    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {original_json_path}")
    print(f"ğŸ“„ ç¿»è¯‘æ–‡ä»¶: {japanese_txt_path}")
    print(f"ğŸ“‹ è¾“å‡ºæ–‡ä»¶: {output_json_path}")
    print(f"ğŸ“ æ€»æ›¿æ¢æ•°é‡: {replaced_count}")
    print(f"ğŸŒ æ—¥è¯­æ–‡æœ¬ä½¿ç”¨: {len(japanese_texts)}/{len(japanese_texts)} (100%)")

def validate_complete_replacement(json_path):
    """
    éªŒè¯å®Œå…¨æ›¿æ¢çš„ç»“æœ
    """
    print(f"\nğŸ” éªŒè¯å®Œå…¨æ›¿æ¢ç»“æœ: {json_path}")
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            slides_data = json.load(f)
        
        japanese_count = 0
        chinese_count = 0
        english_count = 0
        other_count = 0
        total_count = 0
        
        chinese_examples = []
        
        # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬
        for slide in slides_data:
            texts = slide.get('texts', [])
            for text_obj in texts:
                content = text_obj.get('content', '')
                if content.strip():
                    total_count += 1
                    
                    # æ£€æŸ¥æ—¥è¯­å­—ç¬¦ï¼ˆå¹³å‡åã€ç‰‡å‡åã€é•¿éŸ³ç¬¦ç­‰ï¼‰
                    if re.search(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠãƒ¼ã‚¡-ãƒ´]', content):
                        japanese_count += 1
                    # æ£€æŸ¥ä¸­æ–‡å­—ç¬¦
                    elif re.search(r'[\u4e00-\u9fff]', content):
                        chinese_count += 1
                        if len(chinese_examples) < 10:
                            chinese_examples.append(content[:50])
                    # æ£€æŸ¥è‹±æ–‡
                    elif re.search(r'[a-zA-Z]', content):
                        english_count += 1
                    else:
                        other_count += 1
        
        print(f"\nğŸ“ˆ å®Œå…¨æ›¿æ¢ç»Ÿè®¡:")
        print(f"ğŸŒ æ—¥è¯­æ–‡æœ¬: {japanese_count}")
        print(f"ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ–‡æœ¬: {chinese_count}")
        print(f"ğŸ‡ºğŸ‡¸ è‹±æ–‡æ–‡æœ¬: {english_count}")
        print(f"â“ å…¶ä»–æ–‡æœ¬: {other_count}")
        print(f"ğŸ“ æ€»æ–‡æœ¬æ•°: {total_count}")
        
        if total_count > 0:
            japanese_rate = (japanese_count / total_count) * 100
            chinese_rate = (chinese_count / total_count) * 100
            
            print(f"\nğŸ“Š æ—¥è¯­è¦†ç›–ç‡: {japanese_rate:.1f}%")
            print(f"ğŸ“Š ä¸­æ–‡æ®‹ç•™ç‡: {chinese_rate:.1f}%")
            
            if chinese_count == 0:
                print("ğŸ‰ å®Œç¾ï¼æ²¡æœ‰ä¸­æ–‡æ®‹ç•™ï¼")
            else:
                print(f"\nâš ï¸  ä»æœ‰ {chinese_count} æ¡ä¸­æ–‡æ–‡æœ¬æ®‹ç•™:")
                for example in chinese_examples:
                    print(f"   ğŸ“ {example}...")
            
            if japanese_rate >= 95:
                print("âœ… æ—¥è¯­è¦†ç›–ç‡ä¼˜ç§€ï¼")
            elif japanese_rate >= 80:
                print("âœ… æ—¥è¯­è¦†ç›–ç‡è‰¯å¥½ï¼")
            else:
                print("âš ï¸  æ—¥è¯­è¦†ç›–ç‡éœ€è¦æå‡")
    
    except Exception as e:
        print(f"âŒ éªŒè¯æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    original_json = "trip7_ppt_translation/extracted_content/ppt_content.json"
    japanese_txt = "trip7_ppt_translation/extracted_content/ppt_texts_japanese.txt"
    output_json = "trip7_ppt_translation/extracted_content/ppt_content.japanese.json"
    
    print("ğŸš€ å¼€å§‹å®Œå…¨æ›¿æ¢æ—¥è¯­PPTå†…å®¹...")
    print("=" * 60)
    print("ğŸ“‹ å®Œå…¨æ›¿æ¢ç­–ç•¥ï¼š")
    print("   1. æ—¥è¯­txtä¸­çš„å…¨éƒ¨å†…å®¹éƒ½ä¼šå‡ºç°åœ¨JSONä¸­")
    print("   2. ä¸ä¼šæœ‰ä»»ä½•ä¸­æ–‡å†…å®¹æ®‹ç•™")
    print("   3. å¾ªç¯ä½¿ç”¨æ—¥è¯­æ–‡æœ¬ç¡®ä¿å®Œå…¨è¦†ç›–")
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(original_json):
        print(f"âŒ åŸå§‹JSONæ–‡ä»¶ä¸å­˜åœ¨: {original_json}")
        exit(1)
    
    if not os.path.exists(japanese_txt):
        print(f"âŒ æ—¥è¯­ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {japanese_txt}")
        exit(1)
    
    # æ‰§è¡Œå®Œå…¨æ›¿æ¢
    complete_replacement(original_json, japanese_txt, output_json)
    
    # éªŒè¯ç»“æœ
    if os.path.exists(output_json):
        validate_complete_replacement(output_json)
    
    print("\nğŸ‰ å®Œå…¨æ›¿æ¢å¤„ç†å®Œæˆï¼")